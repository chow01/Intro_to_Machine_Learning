{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef00dbf5-6b48-4826-af21-1ceacaefce90",
   "metadata": {},
   "source": [
    "# Cover type classifier research project\n",
    "This notebook consists of the research of classical and modern neural networks researching the classification of covertypes of different terrain. The data set is from UCI, and consists of quantative and qualatative values of the environment. Details can be found in covtype.info\n",
    "\n",
    "## Outline of the data:\n",
    "No missing values\n",
    "\n",
    "Number of instances: 581,012\n",
    "\n",
    "Number of Attributes: 12 measures, but 54 columns of data (10 quantitative variables, 4 binary wilderness areas and 40 binary soil type variables)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97645bb1-a50a-4066-8c88-bf5a3053a544",
   "metadata": {},
   "source": [
    "Name                                     Data Type    Measurement                       Description\n",
    "\n",
    "Elevation                               quantitative    meters                       Elevation in meters\n",
    "\n",
    "Aspect                                  quantitative    azimuth                      Aspect in degrees azimuth\n",
    "\n",
    "Slope                                   quantitative    degrees                      Slope in degrees\n",
    "\n",
    "Horizontal_Distance_To_Hydrology        quantitative    meters                       Horz Dist to nearest surface water features\n",
    "\n",
    "Vertical_Distance_To_Hydrology          quantitative    meters                       Vert Dist to nearest surface water features\n",
    "\n",
    "Horizontal_Distance_To_Roadways         quantitative    meters                       Horz Dist to nearest roadway\n",
    "\n",
    "Hillshade_9am                           quantitative    0 to 255 index               Hillshade index at 9am, summer solstice\n",
    "\n",
    "Hillshade_Noon                          quantitative    0 to 255 index               Hillshade index at noon, summer soltice\n",
    "\n",
    "Hillshade_3pm                           quantitative    0 to 255 index               Hillshade index at 3pm, summer solstice\n",
    "\n",
    "Horizontal_Distance_To_Fire_Points      quantitative    meters                       Horz Dist to nearest wildfire ignition points\n",
    "\n",
    "Wilderness_Area (4 binary columns)      qualitative     0 (absence) or 1 (presence)  Wilderness area designation\n",
    "\n",
    "Soil_Type (40 binary columns)           qualitative     0 (absence) or 1 (presence)  Soil Type designation\n",
    "\n",
    "Cover_Type (7 types)                    integer         1 to 7                       Forest Cover Type designation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404af09-38bc-4f61-8da4-ad51df530c69",
   "metadata": {},
   "source": [
    "### Forest Cover Type Classes:\t\n",
    "1 -- Spruce/Fir\n",
    "\n",
    "2 -- Lodgepole Pine\n",
    "\n",
    "3 -- Ponderosa Pine\n",
    "\n",
    "4 -- Cottonwood/Willow\n",
    "\n",
    "5 -- Aspen\n",
    "\n",
    "6 -- Douglas-fir\n",
    "\n",
    "7 -- Krummholz             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b383ad-5903-4efb-ab54-aa2ae7cae621",
   "metadata": {},
   "source": [
    "## Generate helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402c7ac7-170c-4325-b771-76aaf6772d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "RANDOM_STATE = 77\n",
    "DATA_SET = \"covertype/covtype.data\"\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def split_data(data_set):\n",
    "    # load the data set, string input data_set = \"dataset.csv\"\n",
    "    df = pd.read_csv(data_set, header = None) \n",
    "    df.columns = [\"Elevation\",\n",
    "                  \"Aspect\",\n",
    "                  \"Slope\",\n",
    "                  \"Horizontal_Distance_To_Hydrology\",\n",
    "                  \"Vertical_Distance_To_Hydrology\",\n",
    "                  \"Horizontal_Distance_To_Roadways\",\n",
    "                  \"Hillshade_9am\",\n",
    "                  \"Hillshade_Noon\",\n",
    "                  \"Hillshade_3pm\",\n",
    "                  \"Horizontal_Distance_To_Fire_Points\",\n",
    "                  \"Wilderness_Area1\",\n",
    "                  \"Wilderness_Area2\",\n",
    "                  \"Wilderness_Area3\",\n",
    "                  \"Wilderness_Area4\",\n",
    "                  \"Soil_Type1\",\n",
    "                  \"Soil_Type2\",\n",
    "                  \"Soil_Type3\",\n",
    "                  \"Soil_Type4\",\n",
    "                  \"Soil_Type5\",\n",
    "                  \"Soil_Type6\",\n",
    "                  \"Soil_Type7\",\n",
    "                  \"Soil_Type8\",\n",
    "                  \"Soil_Type9\",\n",
    "                  \"Soil_Type10\",\n",
    "                  \"Soil_Type11\",\n",
    "                  \"Soil_Type12\",\n",
    "                  \"Soil_Type13\",\n",
    "                  \"Soil_Type14\",\n",
    "                  \"Soil_Type15\",\n",
    "                  \"Soil_Type16\",\n",
    "                  \"Soil_Type17\",\n",
    "                  \"Soil_Type18\",\n",
    "                  \"Soil_Type19\",\n",
    "                  \"Soil_Type20\",\n",
    "                  \"Soil_Type21\",\n",
    "                  \"Soil_Type22\",\n",
    "                  \"Soil_Type23\",\n",
    "                  \"Soil_Type24\",\n",
    "                  \"Soil_Type25\",\n",
    "                  \"Soil_Type26\",\n",
    "                  \"Soil_Type27\",\n",
    "                  \"Soil_Type28\",\n",
    "                  \"Soil_Type29\",\n",
    "                  \"Soil_Type30\",\n",
    "                  \"Soil_Type31\",\n",
    "                  \"Soil_Type32\",\n",
    "                  \"Soil_Type33\",\n",
    "                  \"Soil_Type34\",\n",
    "                  \"Soil_Type35\",\n",
    "                  \"Soil_Type36\",\n",
    "                  \"Soil_Type37\",\n",
    "                  \"Soil_Type38\",\n",
    "                  \"Soil_Type39\",\n",
    "                  \"Soil_Type40\",\n",
    "                  \"Cover_Type\"]\n",
    "    df_train, df_test= train_test_split(df, test_size = TEST_SIZE, random_state = RANDOM_STATE, shuffle = True)\n",
    "    X_train = df_train.iloc[:, :-1]     # train features\n",
    "    Y_train = df_train[\"Cover_Type\"]    # train labels\n",
    "    X_test = df_test.iloc[:, :-1]       # test features\n",
    "    Y_test = df_test[\"Cover_Type\"]      # test labels\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "    \n",
    "def knn_trainer(training_features, training_labels):\n",
    "    # n_neighbours = 5, unscaled training\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "    knn.fit(training_features, training_labels)\n",
    "    return knn\n",
    "\n",
    "\n",
    "def tree_trainer(training_features, training_labels):\n",
    "    dtc = DecisionTreeClassifier(random_state = RANDOM_STATE, criterion = \"entropy\")\n",
    "    dtc.fit(training_features, training_labels)\n",
    "    return dtc\n",
    "\n",
    "def svm_trainer(training_features, training_labels):\n",
    "    svm = SVC(kernel = \"linear\", C = 0.01)\n",
    "    svm.fit(training_features, training_labels)\n",
    "    return svm\n",
    "    \n",
    "def gnb_trainer(training_features, training_labels):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(training_features, training_labels)\n",
    "    return gnb\n",
    "\n",
    "def mlp_trainer(training_features, training_labels):\n",
    "    mlp = MLPClassifier(max_iter = 500, random_state = RANDOM_STATE)\n",
    "    mlp.fit(training_features, training_labels)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6a0af5a-8e1a-4096-812b-ef7c0d1678e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Split the data and scale it\n",
    "df_train_features, df_train_labels, df_test_features, df_test_labels = split_data(DATA_SET)\n",
    "scaler = StandardScaler()\n",
    "df_train_features = scaler.fit_transform(df_train_features)    # fit transform fits \"scalar\" to the training set and then transforms it.\n",
    "df_test_features = scaler.transform(df_test_features)          # transform just applies the scalar \"scalar\"\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e91e0-1d4a-499a-9d16-36628916fddf",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4359a81-cf61-46f7-85bd-e2f6b13ba21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn training complete, time taken: 0.19\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "knn = knn_trainer(df_train_features, df_train_labels)\n",
    "time2 = time.time()\n",
    "\n",
    "print(f\"knn training complete, time taken: {(time2-time1):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f245faf-5537-4896-b1a4-10693b2d74cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree training complete, time taken: 8.61\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "tree = tree_trainer(df_train_features,df_train_labels)\n",
    "time2 = time.time()\n",
    "\n",
    "print(f\"tree training complete, time taken: {(time2-time1):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2f420a-6822-44d2-9dec-1debcb0bc4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm #instances trained on: 10000.00\n",
      "svm training complete, time taken: 3.99\n"
     ]
    }
   ],
   "source": [
    "# unscaled   time taken=37.56s C=0.01 #instances=1000\n",
    "# scaled     time taken=3.99s C=0.01 #instances=100000\n",
    "\n",
    "instances = 10000 #len(df_train_features)\n",
    "print(f\"svm #instances trained on: {instances:.2f}\")\n",
    "\n",
    "time1 = time.time()\n",
    "svm = svm_trainer(df_train_features[:instances,:], df_train_labels[:instances])\n",
    "time2 = time.time()\n",
    "\n",
    "print(f\"svm training complete, time taken: {(time2-time1):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e1e7581-f9ea-47b5-a706-2f9d3da72be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnb training complete, time taken: 0.79\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "gnb = gnb_trainer(df_train_features, df_train_labels)\n",
    "time2 = time.time()\n",
    "\n",
    "print(f\"gnb training complete, time taken: {(time2-time1):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edcc6e9f-1b8d-41c7-93ec-0b0488fb4fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp #instances trained on: 10000.00\n",
      "mlp training complete, time taken: 24.43\n"
     ]
    }
   ],
   "source": [
    "# time taken=2.19s  #instances=1000\n",
    "# time taken=24.43s #instances=10000\n",
    "\n",
    "instances = 10000 #len(df_train_features)\n",
    "print(f\"mlp #instances trained on: {instances:.2f}\")\n",
    "\n",
    "time1 = time.time()\n",
    "mlp = mlp_trainer(df_train_features[:instances,:], df_train_labels[:instances])\n",
    "time2 = time.time()\n",
    "\n",
    "print(f\"mlp training complete, time taken: {(time2-time1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088f3a1-a67b-4f86-9dc9-414f8a798281",
   "metadata": {},
   "source": [
    "## Test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d64a92fd-8c31-4965-bc8b-c4a2251f8293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn acc: \n",
      "0.937\n"
     ]
    }
   ],
   "source": [
    "print(\"knn acc: \")\n",
    "\n",
    "# for scaled data\n",
    "print(knn.score(df_test_features[:1000,:],df_test_labels[:1000]))\n",
    "\n",
    "# for unscaled data\n",
    "# print(knn.score(df_test_features.iloc[:1000,:],df_test_labels.iloc[:1000]))\n",
    "\n",
    "# unscaled acc   97.4%\n",
    "# scaled acc     93.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0a802be-a1c3-4b46-9a43-465ca43d23df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree acc: \n",
      "0.952\n"
     ]
    }
   ],
   "source": [
    "print(\"tree acc: \")\n",
    "\n",
    "# for scaled data\n",
    "print(tree.score(df_test_features[:1000,:],df_test_labels[:1000]))\n",
    "\n",
    "# for unscaled data\n",
    "# print(tree.score(df_test_features.iloc[:1000,:],df_test_labels.iloc[:1000]))\n",
    "\n",
    "# unscaled acc   95.1%\n",
    "# scaled acc     95.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ae1f12-4bd2-47d7-b1a9-d338a45d9cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm acc: \n",
      "0.729\n"
     ]
    }
   ],
   "source": [
    "print(\"svm acc: \")\n",
    "\n",
    "# for scaled data\n",
    "print(svm.score(df_test_features[:1000,:],df_test_labels[:1000]))\n",
    "\n",
    "# for unscaled data\n",
    "# print(svm.score(df_test_features.iloc[:1000,:],df_test_labels.iloc[:1000]))\n",
    "\n",
    "\n",
    "# unscaled acc   72.3%\n",
    "# scaled acc     72.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e69ffa73-857f-4ec4-b997-1dd4757eae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnb acc: \n",
      "0.082\n"
     ]
    }
   ],
   "source": [
    "print(\"gnb acc: \")\n",
    "\n",
    "# for scaled data\n",
    "print(gnb.score(df_test_features[:1000,:],df_test_labels[:1000]))\n",
    "\n",
    "# for unscaled data\n",
    "# print(tree.score(df_test_features.iloc[:1000,:],df_test_labels.iloc[:1000]))\n",
    "\n",
    "# unscaled acc   45.5%\n",
    "# scaled acc     8.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "583c52da-c9fd-4bf7-91a7-f2604f1a7264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp acc: \n",
      "0.79\n"
     ]
    }
   ],
   "source": [
    "print(\"mlp acc: \")\n",
    "print(mlp.score(df_test_features[:1000,:],df_test_labels[:1000]))\n",
    "\n",
    "# unscaled acc   60.4%\n",
    "# scaled acc     79.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0783052c-6f55-426f-92df-c0c60e86d5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116203\n"
     ]
    }
   ],
   "source": [
    "print(len(df_test_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a8574-0f08-4017-b01c-3e1115a72ea3",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb4f7b6-bda4-413a-9067-316f0d40502e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp313-cp313-macosx_10_13_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.3-cp313-cp313-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/Cellar/jupyterlab/4.4.5/libexec/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/jupyterlab/4.4.5/libexec/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.2-cp313-cp313-macosx_10_13_x86_64.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.3-cp313-cp313-macosx_14_0_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]2m3/4\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.3 pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n",
    "pip install scikit-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
